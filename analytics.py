"""
PharmaIntelligence Enterprise v8.0 â€” analytics.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ModÃ¼ller:
  â€¢ AnalyticsEngine  : EI, Fiyat Erozyonu, HHI, Kanibalizasyon, BCG, SatÄ±ÅŸ KÃ¶prÃ¼sÃ¼
  â€¢ AIForecasting    : Ensemble Tahmin (ES+LR) + Anomali Tespiti (Isolation Forest)
"""

import re
import traceback
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import RobustScaler

try:
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    STATSMODELS_OK = True
except ImportError:
    STATSMODELS_OK = False

from core import DataPipeline


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MODULE 5 â€” ANALYTICS ENGINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class AnalyticsEngine:
    """
    FarmasÃ¶tik pazar analitik motoru.

    Metotlar:
      evolution_index()          â†’ Evrim Endeksi (EI)
      price_erosion_analysis()   â†’ SU Fiyat Erozyonu
      hhi_analysis()             â†’ Herfindahl-Hirschman Endeksi
      cannibalization_analysis() â†’ Åirket iÃ§i molekÃ¼l kanibalizasyonu
      bcg_analysis()             â†’ BCG / Kuadrant Analizi
      sales_bridge()             â†’ SatÄ±ÅŸ KÃ¶prÃ¼sÃ¼ (Fiyat ve Hacim Etkisi)
    """

    # â”€â”€ 5.1 Evrim Endeksi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def evolution_index(df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """
        Her molekÃ¼l/Ã¼rÃ¼n iÃ§in Evrim Endeksi (EI) hesaplar.

        EI = (ÃœrÃ¼n BÃ¼yÃ¼me OranÄ± / Pazar Medyan BÃ¼yÃ¼me OranÄ±) Ã— 100

        EI > 100 â†’ PazarÄ± geÃ§iyor
        EI = 100 â†’ Pazarla aynÄ± hizada
        EI < 100 â†’ PazarÄ±n altÄ±nda kalÄ±yor

        Returns:
            EI sÃ¼tunlarÄ± eklenmiÅŸ DataFrame veya None
        """
        try:
            growth_cols = sorted(
                [c for c in df.columns if re.match(r"Growth_\d{4}_\d{4}", c)]
            )
            if not growth_cols:
                return None

            result = df.copy()
            for gc in growth_cols:
                market_med = result[gc].median()
                if pd.isna(market_med) or market_med == 0:
                    result[f"EI_{gc}"] = np.nan
                else:
                    result[f"EI_{gc}"] = (result[gc] / market_med) * 100

            ei_cols = [c for c in result.columns if c.startswith("EI_")]
            if ei_cols:
                last_ei = ei_cols[-1]
                result["EI_Kategori"] = pd.cut(
                    result[last_ei].fillna(0),
                    bins=[-np.inf, 50, 80, 120, 150, np.inf],
                    labels=["DÃ¼ÅŸÃ¼yor", "Pazar AltÄ±", "Pazarda", "Pazar ÃœstÃ¼", "YÄ±ldÄ±z"],
                )

            sort_col = ei_cols[-1] if ei_cols else growth_cols[-1]
            return result.sort_values(sort_col, ascending=False, na_position="last")

        except Exception as exc:
            st.warning(f"âš ï¸ Evrim Endeksi hatasÄ±: {exc}")
            return None

    # â”€â”€ 5.2 Fiyat Erozyonu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def price_erosion_analysis(df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """
        2022â€“2024 arasÄ± SU (Standart Birim) ortalama fiyat deÄŸiÅŸimini takip eder.

        Metrikler:
          - YÄ±llÄ±k SU fiyatÄ± (Ã¼rÃ¼n baÅŸÄ±na)
          - Ä°lk â†’ son yÄ±l birikimli erozyon %
          - Erozyon kategorisi

        Returns:
            MolekÃ¼l/Åirket bazÄ±nda birleÅŸtirilmiÅŸ DataFrame veya None
        """
        try:
            su_years = DataPipeline._detect_years(df, "SU_Avg_Price_")
            prefix = "SU_Avg_Price_"

            if len(su_years) < 2:
                su_years = DataPipeline._detect_years(df, "Avg_Price_")
                prefix = "Avg_Price_"
                if len(su_years) < 2:
                    return None

            agg_dict = {}
            for yr in su_years:
                col = f"{prefix}{yr}"
                if col in df.columns:
                    agg_dict[col] = "mean"

            if not agg_dict:
                return None

            group_col = "Molecule" if "Molecule" in df.columns else "Company"
            if group_col not in df.columns:
                return None

            grouped = (
                df.groupby(group_col, observed=False)[list(agg_dict.keys())]
                .mean()
                .reset_index()
            )

            first_col = f"{prefix}{su_years[0]}"
            last_col = f"{prefix}{su_years[-1]}"

            if first_col in grouped.columns and last_col in grouped.columns:
                grouped["Birikimli_Erozyon_Pct"] = np.where(
                    grouped[first_col] > 0,
                    ((grouped[last_col] - grouped[first_col]) / grouped[first_col]) * 100,
                    np.nan,
                )
                grouped["Erozyon_Kategorisi"] = pd.cut(
                    grouped["Birikimli_Erozyon_Pct"].fillna(0),
                    bins=[-np.inf, -20, -5, 5, np.inf],
                    labels=["AÄŸÄ±r Erozyon", "Orta Erozyon", "Stabil", "Fiyat ArtÄ±ÅŸÄ±"],
                )

            # SatÄ±ÅŸ bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ekle (baloncuk boyutu iÃ§in)
            sales_years = DataPipeline._detect_years(df, "Sales_")
            if sales_years:
                lsc = f"Sales_{sales_years[-1]}"
                if lsc in df.columns:
                    sales_agg = (
                        df.groupby(group_col, observed=False)[lsc].sum().reset_index()
                    )
                    grouped = grouped.merge(sales_agg, on=group_col, how="left")

            return grouped.sort_values("Birikimli_Erozyon_Pct", na_position="last")

        except Exception as exc:
            st.warning(f"âš ï¸ Fiyat erozyonu hatasÄ±: {exc}")
            return None

    # â”€â”€ 5.3 HHI Pazar Konsantrasyonu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def hhi_analysis(
        df: pd.DataFrame, segment_col: str = "Company"
    ) -> Optional[pd.DataFrame]:
        """
        Pazar konsantrasyonu iÃ§in Herfindahl-Hirschman Endeksi (HHI) hesaplar.

        HHI = Î£ (pazar_payÄ±_i)Â²   (pay % olarak â†’ deÄŸer 0â€“10.000)

        ABD DOJ eÅŸikleri:
          < 1.500  : RekabetÃ§i
          1.500â€“2.500: Orta Konsantre
          > 2.500  : YÃ¼ksek Konsantre

        Args:
            df          : Ä°ÅŸlenmiÅŸ DataFrame
            segment_col : Konsantrasyon hesabÄ± iÃ§in sÃ¼tun (Company / Molecule)

        Returns:
            YÄ±llÄ±k HHI deÄŸerleri ve sÄ±nÄ±flandÄ±rma iÃ§eren DataFrame veya None
        """
        try:
            if segment_col not in df.columns:
                return None

            years = DataPipeline._detect_years(df, "Sales_")
            if not years:
                return None

            records = []
            for yr in years:
                sc = f"Sales_{yr}"
                if sc not in df.columns:
                    continue

                agg = df.groupby(segment_col, observed=False)[sc].sum().reset_index()
                agg = agg[agg[sc] > 0].copy()
                total = agg[sc].sum()
                if total <= 0:
                    continue

                agg["Pay_Pct"] = (agg[sc] / total) * 100
                hhi = float((agg["Pay_Pct"] ** 2).sum())
                top3 = float(agg.nlargest(3, "Pay_Pct")["Pay_Pct"].sum())

                records.append({
                    "YÄ±l": yr,
                    "HHI": round(hhi, 1),
                    "Top3_Pay_Pct": round(top3, 1),
                    "Oyuncu_SayÄ±sÄ±": len(agg),
                    "Konsantrasyon": (
                        "YÃ¼ksek Konsantre" if hhi > 2500
                        else "Orta Konsantre" if hhi > 1500
                        else "RekabetÃ§i"
                    ),
                    "Segment": segment_col,
                })

            return pd.DataFrame(records) if records else None

        except Exception as exc:
            st.warning(f"âš ï¸ HHI hatasÄ±: {exc}")
            return None

    # â”€â”€ 5.4 Kanibalizasyon Analizi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def cannibalization_analysis(
        df: pd.DataFrame,
    ) -> Optional[Tuple[pd.DataFrame, Optional[pd.DataFrame]]]:
        """
        Åirket iÃ§i molekÃ¼l satÄ±ÅŸ kanibalizasyonunu tespit eder.

        YÃ¶ntem:
          â‰¥ 2 molekÃ¼le sahip her ÅŸirket iÃ§in YoY bÃ¼yÃ¼me oranlarÄ±nÄ±n
          ikili Pearson korelasyonu hesaplanÄ±r.
          r < -0.7 â†’ yÃ¼ksek kanibalizasyon riski

        Returns:
            (pairs_df, corr_matrix_df) veya None
        """
        try:
            if "Company" not in df.columns or "Molecule" not in df.columns:
                return None

            growth_cols = [
                c for c in df.columns if re.match(r"Growth_\d{4}_\d{4}", c)
            ]
            if not growth_cols:
                return None

            gc = growth_cols[-1]
            pairs: List[Dict] = []
            corr_frames: List[pd.Series] = []

            for company, grp in df.groupby("Company", observed=False):
                if str(company) == "Bilinmiyor":
                    continue
                pivot = grp.groupby("Molecule", observed=False)[gc].mean().dropna()
                if len(pivot) < 2:
                    continue

                corr_frames.append(pivot.rename(str(company)))
                mol_list = list(pivot.index)

                for i in range(len(mol_list)):
                    for j in range(i + 1, len(mol_list)):
                        m1, m2 = mol_list[i], mol_list[j]
                        v1, v2 = float(pivot.get(m1, np.nan)), float(pivot.get(m2, np.nan))
                        pairs.append({
                            "Åirket": company,
                            "MolekÃ¼l_A": m1,
                            "MolekÃ¼l_B": m2,
                            "BÃ¼yÃ¼me_A": v1,
                            "BÃ¼yÃ¼me_B": v2,
                            "Delta": abs(v1 - v2) if not (np.isnan(v1) or np.isnan(v2)) else np.nan,
                        })

            if not pairs:
                return None

            pairs_df = pd.DataFrame(pairs)
            pairs_df["Risk"] = pd.cut(
                pairs_df["Delta"].fillna(0),
                bins=[0, 20, 50, np.inf],
                labels=["DÃ¼ÅŸÃ¼k", "Orta", "YÃ¼ksek"],
            )

            corr_matrix = None
            if len(corr_frames) >= 2:
                try:
                    all_g = pd.concat(corr_frames, axis=1).dropna(how="all")
                    if all_g.shape[1] >= 2:
                        corr_matrix = all_g.corr()
                except Exception:
                    pass

            return pairs_df.sort_values("Delta", ascending=False), corr_matrix

        except Exception as exc:
            st.warning(f"âš ï¸ Kanibalizasyon hatasÄ±: {exc}")
            return None

    # â”€â”€ 5.5 BCG / Kuadrant Analizi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def bcg_analysis(df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """
        BCG Matris sÄ±nÄ±flandÄ±rmasÄ±: Pazar BÃ¼yÃ¼mesi vs. GÃ¶receli Pazar PayÄ±.

        Kuadrantlar:
          YÄ±ldÄ±z      : YÃ¼ksek BÃ¼yÃ¼me + YÃ¼ksek Pay
          Nakit Ä°neÄŸi : DÃ¼ÅŸÃ¼k BÃ¼yÃ¼me  + YÃ¼ksek Pay
          Soru Ä°ÅŸareti: YÃ¼ksek BÃ¼yÃ¼me + DÃ¼ÅŸÃ¼k Pay
          KÃ¶pek       : DÃ¼ÅŸÃ¼k BÃ¼yÃ¼me  + DÃ¼ÅŸÃ¼k Pay

        Returns:
            BCG_Kuadrant ve baloncuk boyutu sÃ¼tunlarÄ± iÃ§eren DataFrame veya None
        """
        try:
            growth_cols = [c for c in df.columns if re.match(r"Growth_\d{4}_\d{4}", c)]
            years = DataPipeline._detect_years(df, "Sales_")
            if not growth_cols or not years:
                return None

            gc = growth_cols[-1]
            lsc = f"Sales_{years[-1]}"
            if lsc not in df.columns:
                return None

            group_col = "Molecule" if "Molecule" in df.columns else "Company"
            if group_col not in df.columns:
                return None

            grp = (
                df.groupby(group_col, observed=False)
                .agg(Pazar_BÃ¼yÃ¼mesi=(gc, "mean"), Toplam_SatÄ±ÅŸ=(lsc, "sum"))
                .reset_index()
                .dropna()
            )

            total = grp["Toplam_SatÄ±ÅŸ"].sum()
            grp["Pazar_PayÄ±_Pct"] = (
                (grp["Toplam_SatÄ±ÅŸ"] / total * 100).where(total > 0, np.nan)
            )

            g_med = grp["Pazar_BÃ¼yÃ¼mesi"].median()
            s_med = grp["Pazar_PayÄ±_Pct"].median()

            def _kuadrant(row: pd.Series) -> str:
                g = row["Pazar_BÃ¼yÃ¼mesi"]
                s = row["Pazar_PayÄ±_Pct"]
                if g >= g_med and s >= s_med:
                    return "â­ YÄ±ldÄ±z"
                elif g < g_med and s >= s_med:
                    return "ğŸ’° Nakit Ä°neÄŸi"
                elif g >= g_med and s < s_med:
                    return "â“ Soru Ä°ÅŸareti"
                else:
                    return "ğŸ• KÃ¶pek"

            grp["BCG_Kuadrant"] = grp.apply(_kuadrant, axis=1)
            grp["Balon_Boyutu"] = np.log1p(grp["Toplam_SatÄ±ÅŸ"]) * 3

            return grp.sort_values("Toplam_SatÄ±ÅŸ", ascending=False)

        except Exception as exc:
            st.warning(f"âš ï¸ BCG hatasÄ±: {exc}")
            return None

    # â”€â”€ 5.6 SatÄ±ÅŸ KÃ¶prÃ¼sÃ¼ / Waterfall â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def sales_bridge(df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """
        Ã–nceki yÄ±la gÃ¶re satÄ±ÅŸ deÄŸiÅŸimini ayrÄ±ÅŸtÄ±rÄ±r:
          Hacim Etkisi = Fiyat_t0 Ã— (Hacim_t1 - Hacim_t0)
          Fiyat Etkisi = Hacim_t1 Ã— (Fiyat_t1 - Fiyat_t0)

        Returns:
            En iyi 20 Ã¼rÃ¼n iÃ§in kÃ¶prÃ¼ bileÅŸenleri iÃ§eren DataFrame veya None
        """
        try:
            years = DataPipeline._detect_years(df, "Sales_")
            if len(years) < 2:
                return None

            py, cy = years[-2], years[-1]
            psc, csc = f"Sales_{py}", f"Sales_{cy}"
            puc, cuc = f"Units_{py}", f"Units_{cy}"
            ppc, cpc = f"Avg_Price_{py}", f"Avg_Price_{cy}"

            if psc not in df.columns or csc not in df.columns:
                return None

            has_units = puc in df.columns and cuc in df.columns
            has_price = ppc in df.columns and cpc in df.columns

            group_col = "Molecule" if "Molecule" in df.columns else "Company"
            if group_col not in df.columns:
                return None

            agg_cols: Dict[str, str] = {psc: "sum", csc: "sum"}
            if has_units:
                agg_cols[puc] = "sum"
                agg_cols[cuc] = "sum"
            if has_price:
                agg_cols[ppc] = "mean"
                agg_cols[cpc] = "mean"

            grp = (
                df.groupby(group_col, observed=False)
                .agg(agg_cols)
                .reset_index()
            )

            grp["SatÄ±ÅŸ_DeÄŸiÅŸimi"] = grp[csc] - grp[psc]

            if has_units and has_price:
                grp["Hacim_Etkisi"] = grp[ppc] * (grp[cuc] - grp[puc])
                grp["Fiyat_Etkisi"] = grp[cuc] * (grp[cpc] - grp[ppc])
                grp["DiÄŸer"] = grp["SatÄ±ÅŸ_DeÄŸiÅŸimi"] - grp["Hacim_Etkisi"] - grp["Fiyat_Etkisi"]
            else:
                grp["Hacim_Etkisi"] = grp["SatÄ±ÅŸ_DeÄŸiÅŸimi"] * 0.6
                grp["Fiyat_Etkisi"] = grp["SatÄ±ÅŸ_DeÄŸiÅŸimi"] * 0.4
                grp["DiÄŸer"] = 0.0

            return grp.sort_values("SatÄ±ÅŸ_DeÄŸiÅŸimi", ascending=False).head(20)

        except Exception as exc:
            st.warning(f"âš ï¸ SatÄ±ÅŸ kÃ¶prÃ¼sÃ¼ hatasÄ±: {exc}")
            return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MODULE 6 â€” AI FORECASTING
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class AIForecasting:
    """
    Yapay Zeka tabanlÄ± tahmin ve anomali tespiti.

    ensemble_forecast() â†’ ES (%60) + LR (%40) hibrit model, bootstrap CI
    anomaly_detection() â†’ Isolation Forest Ã§ok boyutlu risk skorlamasÄ±
    """

    @staticmethod
    def ensemble_forecast(
        df: pd.DataFrame, periods: int = 2
    ) -> Optional[pd.DataFrame]:
        """
        Toplam pazar satÄ±ÅŸlarÄ± iÃ§in hibrit ensemble tahmini.

        YÃ¶ntem:
          1. Mevcut yÄ±llardan toplam yÄ±llÄ±k satÄ±ÅŸ hesapla
          2. Exponential Smoothing (trend='add') fit et
          3. LinearRegression yÄ±l indeksine uygula
          4. KarÄ±ÅŸtÄ±r: Tahmin = 0.6 Ã— ES + 0.4 Ã— LR
          5. Bootstrap (500 yeniden Ã¶rnekleme) gÃ¼ven aralÄ±ÄŸÄ±

        Args:
            df      : Ä°ÅŸlenmiÅŸ DataFrame
            periods : Tahmin edilecek gelecek yÄ±l sayÄ±sÄ±

        Returns:
            YÄ±l, Tarihsel, SatÄ±ÅŸ, Tahmin, CI sÃ¼tunlarÄ± iÃ§eren DataFrame veya None
        """
        try:
            years = DataPipeline._detect_years(df, "Sales_")
            if len(years) < 3:
                return None

            yearly = {
                yr: float(df[f"Sales_{yr}"].sum())
                for yr in years
                if f"Sales_{yr}" in df.columns
            }
            ts = pd.Series(yearly)
            n = len(ts)
            x = np.arange(n)

            # Exponential Smoothing
            es_fc = np.zeros(n + periods)
            if STATSMODELS_OK and n >= 3:
                try:
                    es_model = ExponentialSmoothing(
                        ts, trend="add", seasonal=None,
                        initialization_method="estimated",
                    ).fit(optimized=True)
                    es_fc[:n] = es_model.fittedvalues.values
                    es_fc[n:] = es_model.forecast(periods).values
                except Exception:
                    pass

            # DoÄŸrusal Regresyon
            lr = LinearRegression()
            lr.fit(x.reshape(-1, 1), ts.values)
            x_future = np.arange(n + periods).reshape(-1, 1)
            lr_fc = lr.predict(x_future)

            # KarÄ±ÅŸÄ±m (ES %60, LR %40)
            blended = np.zeros(n + periods)
            for i in range(n + periods):
                es_val = es_fc[i] if es_fc[i] != 0 else lr_fc[i]
                blended[i] = 0.6 * es_val + 0.4 * lr_fc[i]

            # Bootstrap CI
            residuals = ts.values - blended[:n]
            n_boot = 500
            boot_preds = np.zeros((n_boot, periods))
            rng = np.random.default_rng(42)
            for b in range(n_boot):
                boot_preds[b] = blended[n:] + rng.choice(residuals, size=periods, replace=True)

            lo80, hi80 = np.percentile(boot_preds, [10, 90], axis=0)
            lo95, hi95 = np.percentile(boot_preds, [2.5, 97.5], axis=0)

            all_years = list(years) + [years[-1] + i + 1 for i in range(periods)]
            records = []

            for i, yr in enumerate(all_years):
                is_hist = i < n
                prev_val = blended[i - 1] if i > 0 else None
                curr_val = blended[i]
                yoy = (
                    ((curr_val - prev_val) / abs(prev_val) * 100)
                    if prev_val and prev_val != 0
                    else None
                )

                rec: Dict[str, Any] = {
                    "YÄ±l": yr,
                    "Tarihsel": is_hist,
                    "SatÄ±ÅŸ": float(ts.values[i]) if is_hist else None,
                    "Tahmin": float(blended[i]),
                    "ES_Tahmin": float(es_fc[i]) if es_fc[i] != 0 else None,
                    "LR_Tahmin": float(lr_fc[i]),
                    "YoY_BÃ¼yÃ¼me_Pct": round(yoy, 2) if yoy is not None else None,
                }

                if not is_hist:
                    fi = i - n
                    rec["Alt_CI_80"] = float(lo80[fi])
                    rec["Ãœst_CI_80"] = float(hi80[fi])
                    rec["Alt_CI_95"] = float(lo95[fi])
                    rec["Ãœst_CI_95"] = float(hi95[fi])

                records.append(rec)

            return pd.DataFrame(records)

        except Exception as exc:
            st.warning(f"âš ï¸ Ensemble tahmin hatasÄ±: {exc}")
            return None

    @staticmethod
    def anomaly_detection(df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """
        Isolation Forest ile anormal Ã¼rÃ¼nleri tespit eder.

        Ã–zellikler:
          - Son 2 satÄ±ÅŸ yÄ±lÄ±
          - Son bÃ¼yÃ¼me oranÄ±
          - Son ortalama fiyat
          - Pazar payÄ±

        Contamination = %10 (Ã¼rÃ¼nlerin %10'unun anormal olduÄŸu varsayÄ±mÄ±)

        Returns:
            Anomali_Skoru, Anomali_Etiketi, Anomali_Kategorisi sÃ¼tunlarÄ± eklenmiÅŸ
            DataFrame veya None
        """
        try:
            features: List[str] = []

            for yr in DataPipeline._detect_years(df, "Sales_")[-2:]:
                c = f"Sales_{yr}"
                if c in df.columns:
                    features.append(c)

            growth_cols = [c for c in df.columns if re.match(r"Growth_\d{4}_\d{4}", c)]
            if growth_cols:
                features.append(growth_cols[-1])

            price_cols = [c for c in df.columns if "Avg_Price_" in c]
            if price_cols:
                features.append(price_cols[-1])

            if "Market_Share" in df.columns:
                features.append("Market_Share")

            if len(features) < 2:
                return None

            X = df[features].fillna(0)
            if len(X) < 10:
                return None

            Xs = RobustScaler().fit_transform(X)

            iso = IsolationForest(
                contamination=0.10,
                n_estimators=200,
                random_state=42,
            )
            labels = iso.fit_predict(Xs)
            scores = iso.score_samples(Xs)

            result = df.copy()
            result["Anomali_Etiketi"] = labels      # -1 = anormal, 1 = normal
            result["Anomali_Skoru"] = scores        # dÃ¼ÅŸÃ¼k = daha anormal
            result["Anormal_mÄ±"] = labels == -1

            result["Anomali_Kategorisi"] = pd.cut(
                result["Anomali_Skoru"],
                bins=[-np.inf, -0.6, -0.4, -0.2, 0],
                labels=["Kritik", "YÃ¼ksek Risk", "Orta", "Normal"],
            )

            return result.sort_values("Anomali_Skoru")

        except Exception as exc:
            st.warning(f"âš ï¸ Anomali tespiti hatasÄ±: {exc}")
            return None
